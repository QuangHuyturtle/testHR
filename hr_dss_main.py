#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HR Decision Support System - Enhanced Version with Required Skills Logic
H·ªá th·ªëng h·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh tuy·ªÉn d·ª•ng nh√¢n s·ª± - Phi√™n b·∫£n n√¢ng cao v·ªõi logic k·ªπ nƒÉng b·∫Øt bu·ªôc

Author: Student  
Date: 2025
Course: H·ªá h·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh, H·ªá ƒëi·ªÅu h√†nh v√† l·∫≠p tr√¨nh Linux
"""

import pandas as pd
import numpy as np
import pickle
import json
import os
import sys
import logging
from datetime import datetime
import argparse
from pathlib import Path

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.pipeline import Pipeline

# Text processing
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Download NLTK data if not exists
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
except LookupError:
    print("ƒêang t·∫£i d·ªØ li·ªáu NLTK...")
    nltk.download('punkt')
    nltk.download('stopwords')
    print("‚úì T·∫£i d·ªØ li·ªáu NLTK ho√†n t·∫•t")

# Setup logging
os.makedirs('logs', exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/hr_dss_enhanced.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class HRDecisionSupportSystemEnhanced:
    """
    H·ªá th·ªëng h·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh tuy·ªÉn d·ª•ng nh√¢n s·ª± - Phi√™n b·∫£n n√¢ng cao v·ªõi logic k·ªπ nƒÉng b·∫Øt bu·ªôc
    """
    
    def __init__(self, model_path="models/", data_path="data/"):
        """
        Kh·ªüi t·∫°o h·ªá th·ªëng HR DSS Enhanced
        
        Args:
            model_path (str): ƒê∆∞·ªùng d·∫´n l∆∞u m√¥ h√¨nh
            data_path (str): ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu
        """
        self.model_path = Path(model_path)
        self.data_path = Path(data_path)
        
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
        self.model_path.mkdir(exist_ok=True)
        self.data_path.mkdir(exist_ok=True)
        
        # Initialize components
        self.model = None
        self.vectorizer = None
        self.scaler = None
        self.label_encoder = None
        self.feature_columns = None
        
        # Load position requirements v√† required skills
        self.position_requirements = self.get_position_requirements()
        self.required_skills_by_position = self.get_required_skills_by_position()
        
        # Load model if exists
        self.load_model()
        
        logger.info("üöÄ H·ªá th·ªëng H·ªó tr·ª£ Ra quy·∫øt ƒë·ªãnh Tuy·ªÉn d·ª•ng (Enhanced) ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")

    def get_required_skills_by_position(self):
        """
        ƒê·ªãnh nghƒ©a k·ªπ nƒÉng b·∫Øt bu·ªôc cho t·ª´ng v·ªã tr√≠/ng√†nh ngh·ªÅ
        """
        return {
            # Data Science & Analytics
            'data_scientist': {
                'required': ['sql', 'python'],  # B·∫Øt bu·ªôc c√≥ √≠t nh·∫•t 1 trong 2
                'preferred': ['machine learning', 'statistics', 'pandas', 'numpy', 'scipy'],
                'bonus': ['deep learning', 'tensorflow', 'pytorch', 'spark', 'hadoop']
            },
            'data_analyst': {
                'required': ['sql', 'excel'],  # B·∫Øt bu·ªôc c√≥ √≠t nh·∫•t 1 trong 2
                'preferred': ['python', 'r', 'tableau', 'powerbi', 'statistics'],
                'bonus': ['machine learning', 'data visualization', 'pandas']
            },
            'business_analyst': {
                'required': ['excel', 'sql'],
                'preferred': ['powerbi', 'tableau', 'business intelligence', 'requirements analysis'],
                'bonus': ['python', 'r', 'process modeling', 'agile']
            },
            
            # Web Development
            'web_developer': {
                'required': ['html', 'css', 'javascript'],  # B·∫Øt bu·ªôc c√≥ t·∫•t c·∫£ 3
                'preferred': ['react', 'vue', 'angular', 'nodejs', 'php'],
                'bonus': ['typescript', 'webpack', 'sass', 'mongodb', 'postgresql']
            },
            'frontend_developer': {
                'required': ['html', 'css', 'javascript'],
                'preferred': ['react', 'vue', 'angular', 'responsive design'],
                'bonus': ['typescript', 'sass', 'webpack', 'figma', 'ui/ux']
            },
            'backend_developer': {
                'required': ['sql', 'api'],  # √çt nh·∫•t 1 ng√¥n ng·ªØ backend
                'preferred': ['nodejs', 'python', 'java', 'php', 'c#', 'go'],
                'bonus': ['microservices', 'docker', 'kubernetes', 'aws', 'azure']
            },
            'fullstack_developer': {
                'required': ['html', 'css', 'javascript', 'sql'],
                'preferred': ['react', 'nodejs', 'python', 'mongodb', 'postgresql'],
                'bonus': ['docker', 'aws', 'microservices', 'devops']
            },
            
            # Software Development
            'software_developer': {
                'required': ['programming'],  # √çt nh·∫•t 1 ng√¥n ng·ªØ l·∫≠p tr√¨nh
                'preferred': ['python', 'java', 'javascript', 'c#', 'c++'],
                'bonus': ['git', 'agile', 'testing', 'ci/cd', 'docker']
            },
            'mobile_developer': {
                'required': ['mobile'],
                'preferred': ['react native', 'flutter', 'swift', 'kotlin', 'java'],
                'bonus': ['firebase', 'push notifications', 'app store', 'google play']
            },
            
            # DevOps & Infrastructure
            'devops_engineer': {
                'required': ['linux', 'docker'],
                'preferred': ['kubernetes', 'aws', 'azure', 'terraform', 'ansible'],
                'bonus': ['monitoring', 'jenkins', 'gitlab ci', 'prometheus', 'grafana']
            },
            'system_administrator': {
                'required': ['linux', 'windows'],
                'preferred': ['networking', 'security', 'bash', 'powershell'],
                'bonus': ['vmware', 'hyper-v', 'active directory', 'monitoring']
            },
            
            # Design
            'ui_ux_designer': {
                'required': ['design', 'ui/ux'],
                'preferred': ['figma', 'sketch', 'adobe creative suite', 'prototyping'],
                'bonus': ['user research', 'wireframing', 'html', 'css']
            },
            'graphic_designer': {
                'required': ['design', 'adobe creative suite'],
                'preferred': ['photoshop', 'illustrator', 'indesign', 'branding'],
                'bonus': ['web design', 'print design', 'typography', 'color theory']
            },
            
            # Marketing & Sales
            'digital_marketer': {
                'required': ['digital marketing'],
                'preferred': ['google ads', 'facebook ads', 'seo', 'sem', 'analytics'],
                'bonus': ['content marketing', 'email marketing', 'social media', 'conversion optimization']
            },
            'content_creator': {
                'required': ['content writing', 'communication'],
                'preferred': ['seo', 'social media', 'copywriting', 'content strategy'],
                'bonus': ['video editing', 'graphic design', 'analytics', 'wordpress']
            },
            
            # Management
            'project_manager': {
                'required': ['project management'],
                'preferred': ['agile', 'scrum', 'pmp', 'leadership', 'communication'],
                'bonus': ['jira', 'confluence', 'risk management', 'stakeholder management']
            },
            'product_manager': {
                'required': ['product management', 'communication'],
                'preferred': ['agile', 'user research', 'analytics', 'roadmap planning'],
                'bonus': ['technical skills', 'sql', 'wireframing', 'a/b testing']
            },
            
            # Quality Assurance
            'qa_engineer': {
                'required': ['testing', 'quality assurance'],
                'preferred': ['automation testing', 'selenium', 'manual testing', 'bug tracking'],
                'bonus': ['api testing', 'performance testing', 'security testing', 'ci/cd']
            },
            
            # Generic positions
            'analyst': {
                'required': ['excel', 'data analysis'],
                'preferred': ['sql', 'statistics', 'reporting'],
                'bonus': ['python', 'r', 'tableau', 'powerbi']
            },
            'developer': {
                'required': ['programming'],
                'preferred': ['python', 'java', 'javascript', 'sql'],
                'bonus': ['git', 'agile', 'testing']
            },
            'designer': {
                'required': ['design'],
                'preferred': ['adobe creative suite', 'figma', 'ui/ux'],
                'bonus': ['html', 'css', 'prototyping']
            }
        }

    def get_position_requirements(self):
        """
        ƒê·ªãnh nghƒ©a y√™u c·∫ßu kinh nghi·ªám t·ªëi thi·ªÉu cho t·ª´ng lo·∫°i v·ªã tr√≠
        """
        return {
            # Senior positions - y√™u c·∫ßu kinh nghi·ªám cao
            'senior_data_scientist': {'min_years': 5, 'min_education': 'bachelor'},
            'senior_developer': {'min_years': 5, 'min_education': 'bachelor'},
            'senior_analyst': {'min_years': 5, 'min_education': 'bachelor'}, 
            'lead': {'min_years': 4, 'min_education': 'bachelor'},
            'manager': {'min_years': 3, 'min_education': 'bachelor'},
            'director': {'min_years': 7, 'min_education': 'master'},
            'principal_engineer': {'min_years': 8, 'min_education': 'bachelor'},
            
            # Mid-level positions
            'data_scientist': {'min_years': 2, 'min_education': 'bachelor'},
            'web_developer': {'min_years': 2, 'min_education': 'bachelor'},
            'software_developer': {'min_years': 2, 'min_education': 'bachelor'},
            'fullstack_developer': {'min_years': 3, 'min_education': 'bachelor'},
            'devops_engineer': {'min_years': 3, 'min_education': 'bachelor'},
            'product_manager': {'min_years': 3, 'min_education': 'bachelor'},
            'project_manager': {'min_years': 2, 'min_education': 'bachelor'},
            
            # Entry-level positions
            'junior_developer': {'min_years': 0, 'min_education': 'bachelor'},
            'junior_analyst': {'min_years': 0, 'min_education': 'bachelor'},
            'frontend_developer': {'min_years': 1, 'min_education': 'associate'},
            'backend_developer': {'min_years': 1, 'min_education': 'bachelor'},
            'data_analyst': {'min_years': 1, 'min_education': 'bachelor'},
            'qa_engineer': {'min_years': 1, 'min_education': 'bachelor'},
            'ui_ux_designer': {'min_years': 1, 'min_education': 'associate'},
            'graphic_designer': {'min_years': 1, 'min_education': 'associate'},
            
            # Generic positions
            'intern': {'min_years': 0, 'min_education': 'high_school'},
            'fresher': {'min_years': 0, 'min_education': 'bachelor'},
            'coordinator': {'min_years': 0, 'min_education': 'associate'},
            'designer': {'min_years': 0, 'min_education': 'associate'},
            'analyst': {'min_years': 1, 'min_education': 'bachelor'},
            'developer': {'min_years': 1, 'min_education': 'bachelor'},
        }

    def check_required_skills(self, candidate_skills, position):
        """
        Ki·ªÉm tra k·ªπ nƒÉng b·∫Øt bu·ªôc cho v·ªã tr√≠ c·ª• th·ªÉ
        
        Args:
            candidate_skills (str): K·ªπ nƒÉng c·ªßa ·ª©ng vi√™n (chu·ªói ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y)
            position (str): V·ªã tr√≠ ·ª©ng tuy·ªÉn
            
        Returns:
            dict: K·∫øt qu·∫£ ki·ªÉm tra k·ªπ nƒÉng
        """
        # Chu·∫©n h√≥a k·ªπ nƒÉng ·ª©ng vi√™n
        candidate_skills_list = [skill.strip().lower() for skill in candidate_skills.split(',')]
        
        # T√¨m y√™u c·∫ßu k·ªπ nƒÉng cho v·ªã tr√≠
        position_lower = position.lower().replace(' ', '_')
        skill_requirements = None
        
        # T√¨m ki·∫øm ch√≠nh x√°c tr∆∞·ªõc
        if position_lower in self.required_skills_by_position:
            skill_requirements = self.required_skills_by_position[position_lower]
        else:
            # T√¨m ki·∫øm m·ªù - t√¨m v·ªã tr√≠ c√≥ ch·ª©a t·ª´ kh√≥a
            for req_position, req_data in self.required_skills_by_position.items():
                if any(keyword in position_lower for keyword in req_position.split('_')):
                    skill_requirements = req_data
                    break
                elif any(keyword in req_position for keyword in position_lower.split('_')):
                    skill_requirements = req_data
                    break
        
        if not skill_requirements:
            # Kh√¥ng t√¨m th·∫•y y√™u c·∫ßu c·ª• th·ªÉ, s·ª≠ d·ª•ng y√™u c·∫ßu chung
            return {
                'has_required_skills': True,
                'missing_required': [],
                'matching_preferred': [],
                'matching_bonus': [],
                'skill_score': 5.0,  # ƒêi·ªÉm trung b√¨nh
                'feedback': ['‚ö† Kh√¥ng t√¨m th·∫•y y√™u c·∫ßu k·ªπ nƒÉng c·ª• th·ªÉ cho v·ªã tr√≠ n√†y'],
                'requirements_found': False
            }
        
        # Ki·ªÉm tra k·ªπ nƒÉng b·∫Øt bu·ªôc
        required_skills = skill_requirements.get('required', [])
        preferred_skills = skill_requirements.get('preferred', [])
        bonus_skills = skill_requirements.get('bonus', [])
        
        # Logic ki·ªÉm tra k·ªπ nƒÉng b·∫Øt bu·ªôc
        missing_required = []
        has_required_skills = True
        
        if required_skills:
            # Ki·ªÉm tra t·ª´ng k·ªπ nƒÉng b·∫Øt bu·ªôc
            for req_skill in required_skills:
                found = any(req_skill.lower() in candidate_skill for candidate_skill in candidate_skills_list)
                if not found:
                    missing_required.append(req_skill)
            
            # N·∫øu thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc
            if missing_required:
                has_required_skills = False
        
        # ƒê·∫øm k·ªπ nƒÉng preferred v√† bonus
        matching_preferred = []
        matching_bonus = []
        
        for pref_skill in preferred_skills:
            if any(pref_skill.lower() in candidate_skill for candidate_skill in candidate_skills_list):
                matching_preferred.append(pref_skill)
        
        for bonus_skill in bonus_skills:
            if any(bonus_skill.lower() in candidate_skill for candidate_skill in candidate_skills_list):
                matching_bonus.append(bonus_skill)
        
        # T√≠nh ƒëi·ªÉm k·ªπ nƒÉng (0-10)
        skill_score = 0
        if has_required_skills:
            skill_score += 6  # 6 ƒëi·ªÉm c∆° b·∫£n khi c√≥ ƒë·ªß k·ªπ nƒÉng b·∫Øt bu·ªôc
            skill_score += min(len(matching_preferred) * 0.5, 2)  # T·ªëi ƒëa 2 ƒëi·ªÉm t·ª´ preferred
            skill_score += min(len(matching_bonus) * 0.25, 2)  # T·ªëi ƒëa 2 ƒëi·ªÉm t·ª´ bonus
        else:
            # N·∫øu thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc, ch·ªâ t√≠nh ƒëi·ªÉm t·ª´ preferred v√† bonus
            skill_score += min(len(matching_preferred) * 0.3, 3)
            skill_score += min(len(matching_bonus) * 0.15, 2)
        
        skill_score = min(skill_score, 10)  # Gi·ªõi h·∫°n t·ªëi ƒëa 10 ƒëi·ªÉm
        
        # T·∫°o feedback
        feedback = []
        if has_required_skills:
            feedback.append(f"‚úì C√≥ ƒë·ªß k·ªπ nƒÉng b·∫Øt bu·ªôc cho v·ªã tr√≠ {position}")
        else:
            feedback.append(f"‚úó Thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc: {', '.join(missing_required)}")
        
        if matching_preferred:
            feedback.append(f"‚úì C√≥ {len(matching_preferred)} k·ªπ nƒÉng ∆∞u ti√™n: {', '.join(matching_preferred)}")
        
        if matching_bonus:
            feedback.append(f"‚≠ê C√≥ {len(matching_bonus)} k·ªπ nƒÉng bonus: {', '.join(matching_bonus)}")
        
        return {
            'has_required_skills': has_required_skills,
            'missing_required': missing_required,
            'matching_preferred': matching_preferred,
            'matching_bonus': matching_bonus,
            'skill_score': skill_score,
            'feedback': feedback,
            'requirements_found': True
        }

    def get_education_score(self, education_level):
        """Chuy·ªÉn ƒë·ªïi tr√¨nh ƒë·ªô h·ªçc v·∫•n th√†nh ƒëi·ªÉm s·ªë"""
        education_mapping = {
            'high_school': 1,
            'associate': 2, 
            'bachelor': 3,
            'master': 4,
            'phd': 5
        }
        return education_mapping.get(education_level.lower(), 1)

    def enhanced_suitability_logic(self, candidate_data):
        """
        Logic ƒë√°nh gi√° n√¢ng cao v·ªõi ki·ªÉm tra k·ªπ nƒÉng b·∫Øt bu·ªôc theo v·ªã tr√≠
        """
        years_exp = int(candidate_data.get('years_experience', 0))
        education = candidate_data.get('education_level', 'high_school').lower()
        skills = candidate_data.get('skills', '').lower()
        position = candidate_data.get('position_applied', '').lower()
        
        # T√¨m y√™u c·∫ßu v·ªã tr√≠
        position_req = None
        for req_position, req_data in self.position_requirements.items():
            if req_position in position or position in req_position:
                position_req = req_data
                break
        
        if position_req is None:
            # Ph√¢n lo·∫°i d·ª±a tr√™n t·ª´ kh√≥a trong t√™n v·ªã tr√≠
            if any(word in position for word in ['senior', 'lead', 'manager', 'director']):
                position_req = {'min_years': 4, 'min_education': 'bachelor'}
            elif any(word in position for word in ['scientist', 'specialist']):
                position_req = {'min_years': 3, 'min_education': 'bachelor'}
            elif any(word in position for word in ['junior', 'intern', 'fresher']):
                position_req = {'min_years': 0, 'min_education': 'bachelor'}
            else:
                position_req = {'min_years': 1, 'min_education': 'bachelor'}
        
        # Ki·ªÉm tra k·ªπ nƒÉng b·∫Øt bu·ªôc
        skill_check = self.check_required_skills(skills, position)
        
        # T√≠nh ƒëi·ªÉm ƒë√°nh gi√°
        score = 0
        max_score = 10
        feedback = []
        
        # 1. Ki·ªÉm tra k·ªπ nƒÉng b·∫Øt bu·ªôc (50% tr·ªçng s·ªë - quan tr·ªçng nh·∫•t)
        if skill_check['has_required_skills']:
            score += 5  # Full ƒëi·ªÉm k·ªπ nƒÉng b·∫Øt bu·ªôc
            feedback.extend(skill_check['feedback'])
        else:
            score += 1  # ƒêi·ªÉm r·∫•t th·∫•p n·∫øu thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc
            feedback.extend(skill_check['feedback'])
        
        # 2. Ki·ªÉm tra kinh nghi·ªám (30% tr·ªçng s·ªë)
        min_years = position_req['min_years']
        if years_exp >= min_years + 3:
            score += 3  # V∆∞·ª£t y√™u c·∫ßu nhi·ªÅu
            feedback.append(f"‚úì Kinh nghi·ªám v∆∞·ª£t y√™u c·∫ßu nhi·ªÅu ({years_exp} nƒÉm >> {min_years} nƒÉm)")
        elif years_exp >= min_years + 1:
            score += 2.5  # V∆∞·ª£t y√™u c·∫ßu
            feedback.append(f"‚úì Kinh nghi·ªám v∆∞·ª£t y√™u c·∫ßu ({years_exp} nƒÉm > {min_years} nƒÉm)")
        elif years_exp >= min_years:
            score += 2  # ƒê·∫°t y√™u c·∫ßu
            feedback.append(f"‚úì Kinh nghi·ªám ƒë·∫°t y√™u c·∫ßu ({years_exp} nƒÉm >= {min_years} nƒÉm)")
        elif years_exp >= min_years - 1 and min_years > 0:
            score += 1.5  # G·∫ßn ƒë·∫°t y√™u c·∫ßu
            feedback.append(f"‚ö† Kinh nghi·ªám g·∫ßn ƒë·∫°t y√™u c·∫ßu ({years_exp} nƒÉm, y√™u c·∫ßu {min_years} nƒÉm)")
        else:
            score += 0.5  # Thi·∫øu kinh nghi·ªám
            feedback.append(f"‚úó Kinh nghi·ªám ch∆∞a ƒë·∫°t y√™u c·∫ßu ({years_exp} nƒÉm < {min_years} nƒÉm)")
        
        # 3. Ki·ªÉm tra h·ªçc v·∫•n (20% tr·ªçng s·ªë)
        min_education = position_req['min_education']
        candidate_edu_score = self.get_education_score(education)
        min_edu_score = self.get_education_score(min_education)
        
        if candidate_edu_score >= min_edu_score + 1:
            score += 2  # V∆∞·ª£t y√™u c·∫ßu
            feedback.append(f"‚úì H·ªçc v·∫•n v∆∞·ª£t y√™u c·∫ßu ({education} > {min_education})")
        elif candidate_edu_score >= min_edu_score:
            score += 1.5  # ƒê·∫°t y√™u c·∫ßu
            feedback.append(f"‚úì H·ªçc v·∫•n ƒë·∫°t y√™u c·∫ßu ({education} >= {min_education})")
        else:
            score += 0.5  # Ch∆∞a ƒë·∫°t y√™u c·∫ßu
            feedback.append(f"‚úó H·ªçc v·∫•n ch∆∞a ƒë·∫°t y√™u c·∫ßu ({education} < {min_education})")
        
        # T√≠nh to√°n k·∫øt qu·∫£ cu·ªëi c√πng
        percentage = (score / max_score) * 100
        
        # Quy·∫øt ƒë·ªãnh cu·ªëi c√πng - nghi√™m ng·∫∑t h∆°n v·ªõi k·ªπ nƒÉng b·∫Øt bu·ªôc
        suitable = False
        confidence_level = "Th·∫•p"
        
        if skill_check['has_required_skills']:
            if score >= 8.5:  # 85%
                suitable = True
                confidence_level = "R·∫•t cao"
                recommendation = "R·∫•t khuy·∫øn kh√≠ch m·ªùi ph·ªèng v·∫•n ngay"
            elif score >= 7:  # 70%
                suitable = True  
                confidence_level = "Cao"
                recommendation = "Khuy·∫øn kh√≠ch m·ªùi ph·ªèng v·∫•n"
            elif score >= 5.5:  # 55%
                suitable = True
                confidence_level = "Trung b√¨nh"
                recommendation = "C√≥ th·ªÉ m·ªùi ph·ªèng v·∫•n"
            else:
                suitable = False
                confidence_level = "Th·∫•p"
                recommendation = "C·∫ßn c·∫£i thi·ªán th√™m"
        else:
            # N·∫øu thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc, r·∫•t kh√≥ ƒë∆∞·ª£c ch·∫•p nh·∫≠n
            if score >= 7:  # C·∫ßn ƒëi·ªÉm r·∫•t cao t·ª´ kinh nghi·ªám + h·ªçc v·∫•n
                suitable = True
                confidence_level = "Th·∫•p"
                recommendation = "C·∫ßn ƒë√°nh gi√° k·ªπ nƒÉng trong ph·ªèng v·∫•n"
            else:
                suitable = False
                confidence_level = "R·∫•t th·∫•p"
                recommendation = "Kh√¥ng ph√π h·ª£p - thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc"
        
        return {
            'suitable': suitable,
            'score': score,
            'max_score': max_score,
            'percentage': percentage,
            'confidence_level': confidence_level,
            'recommendation': recommendation,
            'feedback': feedback,
            'position_requirements': {
                'min_years': min_years,
                'min_education': min_education,
                'position': position
            },
            'skill_analysis': skill_check
        }
    
    def preprocess_text(self, text):
        """
        Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n (CV, m√¥ t·∫£ k·ªπ nƒÉng)
        """
        if pd.isna(text) or text is None:
            return ""
        
        # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng
        text = str(text).lower()
        
        # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, gi·ªØ l·∫°i ch·ªØ c√°i v√† s·ªë
        text = re.sub(r'[^a-zA-Z0-9\s]', ' ', text)
        
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Tokenize v√† lo·∫°i b·ªè stop words
        try:
            tokens = word_tokenize(text)
            stop_words = set(stopwords.words('english'))
            tokens = [token for token in tokens if token not in stop_words and len(token) > 2]
            return ' '.join(tokens)
        except:
            return text
    
    def create_sample_data(self, num_samples=1000):
        """
        T·∫°o d·ªØ li·ªáu m·∫´u cho training v·ªõi logic n√¢ng cao
        """
        logger.info(f"üé≤ T·∫°o d·ªØ li·ªáu m·∫´u v·ªõi {num_samples} m·∫´u (logic k·ªπ nƒÉng n√¢ng cao)...")
        
        np.random.seed(42)
        
        # Danh s√°ch k·ªπ nƒÉng theo ng√†nh
        all_skills = []
        for pos_skills in self.required_skills_by_position.values():
            all_skills.extend(pos_skills.get('required', []))
            all_skills.extend(pos_skills.get('preferred', []))
            all_skills.extend(pos_skills.get('bonus', []))
        
        # Th√™m c√°c k·ªπ nƒÉng chung
        additional_skills = [
            'communication', 'teamwork', 'problem solving', 'time management',
            'critical thinking', 'creativity', 'adaptability', 'leadership'
        ]
        
        skills_pool = list(set(all_skills + additional_skills))
        
        education_levels = ['high_school', 'associate', 'bachelor', 'master', 'phd']
        positions = list(self.required_skills_by_position.keys())
        
        data = []
        
        for i in range(num_samples):
            # Random position
            position = np.random.choice(positions)
            
            # Kinh nghi·ªám ph√π h·ª£p v·ªõi v·ªã tr√≠
            pos_req = self.position_requirements.get(position, {'min_years': 1, 'min_education': 'bachelor'})
            min_years = pos_req['min_years']
            
            # Random kinh nghi·ªám v·ªõi bias theo y√™u c·∫ßu v·ªã tr√≠
            if np.random.random() < 0.7:  # 70% c√≥ kinh nghi·ªám ph√π h·ª£p ho·∫∑c cao h∆°n
                years_exp = np.random.randint(min_years, min_years + 10)
            else:  # 30% c√≥ kinh nghi·ªám th·∫•p h∆°n y√™u c·∫ßu
                years_exp = np.random.randint(0, min_years + 1)
            
            # Random education
            education = np.random.choice(education_levels)
            
            # T·∫°o skills c√≥ bias theo y√™u c·∫ßu v·ªã tr√≠
            skill_req = self.required_skills_by_position.get(position, {})
            required_skills = skill_req.get('required', [])
            preferred_skills = skill_req.get('preferred', [])
            bonus_skills = skill_req.get('bonus', [])
            
            candidate_skills = []
            
            # 60% chance c√≥ ƒë·ªß k·ªπ nƒÉng b·∫Øt bu·ªôc
            if np.random.random() < 0.6 and required_skills:
                candidate_skills.extend(required_skills)
            
            # Random preferred skills
            if preferred_skills:
                num_preferred = np.random.randint(0, min(len(preferred_skills), 4))
                candidate_skills.extend(np.random.choice(preferred_skills, num_preferred, replace=False))
            
            # Random bonus skills
            if bonus_skills:
                num_bonus = np.random.randint(0, min(len(bonus_skills), 3))
                candidate_skills.extend(np.random.choice(bonus_skills, num_bonus, replace=False))
            
            # Th√™m m·ªôt s·ªë k·ªπ nƒÉng random
            num_random = np.random.randint(1, 4)
            random_skills = np.random.choice(additional_skills, num_random, replace=False)
            candidate_skills.extend(random_skills)
            
            # Lo·∫°i b·ªè duplicate v√† t·∫°o string
            candidate_skills = list(set(candidate_skills))
            skills_str = ', '.join(candidate_skills)
            
            # Experience description
            exp_desc = f"Experienced {position.replace('_', ' ')} with {years_exp} years working with {', '.join(candidate_skills[:3])}"
            
            # S·ª≠ d·ª•ng logic n√¢ng cao ƒë·ªÉ t·∫°o nh√£n
            candidate_data = {
                'years_experience': years_exp,
                'education_level': education,
                'skills': skills_str,
                'position_applied': position
            }
            
            assessment = self.enhanced_suitability_logic(candidate_data)
            suitable = 1 if assessment['suitable'] else 0
            
            data.append({
                'candidate_id': f'CAND_{i+1:04d}',
                'years_experience': years_exp,
                'education_level': education,
                'skills': skills_str,
                'experience_description': exp_desc,
                'position_applied': position,
                'suitable': suitable
            })
        
        df = pd.DataFrame(data)
        
        # Save sample data
        sample_file = self.data_path / 'sample_candidates_enhanced.csv'
        df.to_csv(sample_file, index=False)
        logger.info(f"‚úì D·ªØ li·ªáu m·∫´u n√¢ng cao ƒë√£ l∆∞u t·∫°i {sample_file}")
        
        return df

    def extract_features(self, df):
        """
        Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu ·ª©ng vi√™n
        """
        logger.info("üìä ƒêang tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu ·ª©ng vi√™n...")
        
        # T·∫°o b·∫£n sao ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng d·ªØ li·ªáu g·ªëc
        processed_df = df.copy()
        
        # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
        processed_df['skills_processed'] = processed_df['skills'].apply(self.preprocess_text)
        processed_df['experience_description_processed'] = processed_df['experience_description'].apply(self.preprocess_text)
        
        # K·∫øt h·ª£p c√°c tr∆∞·ªùng vƒÉn b·∫£n
        processed_df['combined_text'] = (
            processed_df['skills_processed'] + ' ' + 
            processed_df['experience_description_processed']
        )
        
        # T√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng s·ªë
        processed_df['education_score'] = processed_df['education_level'].apply(self.get_education_score)
        
        # Chu·∫©n h√≥a kinh nghi·ªám
        processed_df['years_experience'] = pd.to_numeric(processed_df['years_experience'], errors='coerce').fillna(0)
        
        # T√≠nh ƒëi·ªÉm k·ªπ nƒÉng
        processed_df['num_skills'] = processed_df['skills'].str.count(',') + 1
        processed_df['num_skills'] = processed_df['num_skills'].fillna(0)
        
        # T√≠nh ƒëi·ªÉm k·ªπ nƒÉng b·∫Øt bu·ªôc cho t·ª´ng ·ª©ng vi√™n
        skill_scores = []
        for _, row in processed_df.iterrows():
            skill_check = self.check_required_skills(row['skills'], row['position_applied'])
            skill_scores.append(skill_check['skill_score'])
        
        processed_df['skill_score'] = skill_scores
        
        logger.info("‚úì Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ho√†n t·∫•t")
        return processed_df
    
    def train_model(self, df=None):
        """
        Training m√¥ h√¨nh ph√¢n lo·∫°i v·ªõi logic n√¢ng cao
        """
        logger.info("üß† B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi logic k·ªπ nƒÉng n√¢ng cao...")
        
        if df is None:
            logger.info("üì¶ T·∫°o d·ªØ li·ªáu m·∫´u v·ªõi logic n√¢ng cao...")
            df = self.create_sample_data()
        
        # Extract features
        logger.info("üîß Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu...")
        processed_df = self.extract_features(df)
        
        # Prepare text features
        if self.vectorizer is None:
            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        
        logger.info("üìù X·ª≠ l√Ω ƒë·∫∑c tr∆∞ng vƒÉn b·∫£n...")
        text_features = self.vectorizer.fit_transform(processed_df['combined_text'])
        
        # Prepare numerical features
        numerical_cols = ['education_score', 'years_experience', 'num_skills', 'skill_score']
        self.feature_columns = numerical_cols
        
        if self.scaler is None:
            self.scaler = StandardScaler()
        
        logger.info("üìè Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng s·ªë...")
        numerical_features = self.scaler.fit_transform(processed_df[numerical_cols])
        
        # Combine features
        X_text = text_features.toarray()
        X_numerical = numerical_features
        X = np.hstack([X_text, X_numerical])
        
        # Target variable
        y = processed_df['suitable']
        
        logger.info(f"üìä T·ªïng s·ªë m·∫´u: {len(X)}")
        logger.info(f"üéØ S·ªë ƒë·∫∑c tr∆∞ng: {X.shape[1]}")
        logger.info(f"‚öñÔ∏è Ph√¢n ph·ªëi nh√£n - Ph√π h·ª£p: {y.sum()}, Ch∆∞a ph√π h·ª£p: {len(y) - y.sum()}")
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        logger.info(f"üî® D·ªØ li·ªáu hu·∫•n luy·ªán: {len(X_train)} m·∫´u")
        logger.info(f"üîç D·ªØ li·ªáu ki·ªÉm th·ª≠: {len(X_test)} m·∫´u")
        
        # Train model
        logger.info("üå≤ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh Random Forest...")
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=12,
            random_state=42,
            class_weight='balanced'
        )
        
        self.model.fit(X_train, y_train)
        
        # Evaluate model
        logger.info("üìà ƒê√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh...")
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        logger.info(f"üéâ Hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t!")
        logger.info(f"üèÜ ƒê·ªô ch√≠nh x√°c: {accuracy:.3f}")
        logger.info(f"üìã B√°o c√°o ph√¢n lo·∫°i:\n{classification_report(y_test, y_pred)}")
        
        # Save model
        logger.info("üíæ L∆∞u m√¥ h√¨nh...")
        self.save_model()
        
        return accuracy
    
    def predict_candidate(self, candidate_data):
        """
        D·ª± ƒëo√°n ƒë·ªô ph√π h·ª£p c·ªßa ·ª©ng vi√™n s·ª≠ d·ª•ng c·∫£ ML model v√† logic n√¢ng cao
        """
        if self.model is None:
            # N·∫øu ch∆∞a c√≥ model, ch·ªâ s·ª≠ d·ª•ng logic n√¢ng cao
            logger.warning("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh ML, s·ª≠ d·ª•ng logic ƒë√°nh gi√° n√¢ng cao")
            assessment = self.enhanced_suitability_logic(candidate_data)
            
            result = {
                'candidate_id': candidate_data.get('candidate_id', 'Kh√¥ng x√°c ƒë·ªãnh'),
                'prediction': 'Suitable' if assessment['suitable'] else 'Not Suitable',
                'prediction_vietnamese': 'Ph√π h·ª£p' if assessment['suitable'] else 'Ch∆∞a ph√π h·ª£p',
                'confidence': assessment['percentage'] / 100,
                'probability_suitable': assessment['percentage'] / 100,
                'recommendation': assessment['recommendation'],
                'recommendation_vietnamese': assessment['recommendation'],
                'education_display': self.get_education_vietnamese(candidate_data.get('education_level', '')),
                'summary': self.generate_candidate_summary_vietnamese(candidate_data, assessment['suitable'], assessment['percentage'] / 100),
                'detailed_feedback': assessment['feedback'],
                'position_requirements': assessment['position_requirements'],
                'skill_analysis': assessment['skill_analysis'],
                'assessment_method': 'Enhanced Logic Only'
            }
            
            logger.info(f"üéØ ƒê√°nh gi√° logic cho {result['candidate_id']}: {result['prediction_vietnamese']} ({result['confidence']:.3f})")
            return result
        
        # S·ª≠ d·ª•ng c·∫£ ML model v√† logic n√¢ng cao
        # Convert to DataFrame
        df = pd.DataFrame([candidate_data])
        
        # Extract features
        processed_df = self.extract_features(df)
        
        # Prepare features
        text_features = self.vectorizer.transform(processed_df['combined_text'])
        numerical_features = self.scaler.transform(processed_df[self.feature_columns])
        
        # Combine features
        X_text = text_features.toarray()
        X_numerical = numerical_features
        X = np.hstack([X_text, X_numerical])
        
        # ML Prediction
        ml_prediction = self.model.predict(X)[0]
        ml_probability = self.model.predict_proba(X)[0]
        
        # Logic Assessment
        logic_assessment = self.enhanced_suitability_logic(candidate_data)
        
        # Combine both approaches v·ªõi tr·ªçng s·ªë m·ªõi
        ml_confidence = max(ml_probability)
        logic_confidence = logic_assessment['percentage'] / 100
        
        # Tr·ªçng s·ªë: 40% ML, 60% Logic (∆∞u ti√™n logic h∆°n)
        final_confidence = 0.4 * ml_confidence + 0.6 * logic_confidence
        
        # Quy·∫øt ƒë·ªãnh cu·ªëi c√πng: Logic c√≥ quy·ªÅn veto n·∫øu thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc
        if not logic_assessment['skill_analysis']['has_required_skills']:
            final_suitable = False  # Veto n·∫øu thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc
            final_confidence = min(final_confidence, 0.4)  # Gi·ªõi h·∫°n confidence
        else:
            final_suitable = (ml_prediction == 1 and logic_assessment['suitable']) or final_confidence > 0.75
        
        result = {
            'candidate_id': candidate_data.get('candidate_id', 'Kh√¥ng x√°c ƒë·ªãnh'),
            'prediction': 'Suitable' if final_suitable else 'Not Suitable',
            'prediction_vietnamese': 'Ph√π h·ª£p' if final_suitable else 'Ch∆∞a ph√π h·ª£p',
            'confidence': final_confidence,
            'probability_suitable': final_confidence,
            'recommendation': self.get_recommendation_vietnamese(1 if final_suitable else 0, final_confidence),
            'recommendation_vietnamese': self.get_recommendation_vietnamese(1 if final_suitable else 0, final_confidence),
            'education_display': self.get_education_vietnamese(candidate_data.get('education_level', '')),
            'summary': self.generate_candidate_summary_vietnamese(candidate_data, final_suitable, final_confidence),
            'detailed_feedback': logic_assessment['feedback'],
            'position_requirements': logic_assessment['position_requirements'],
            'skill_analysis': logic_assessment['skill_analysis'],
            'ml_prediction': 'Suitable' if ml_prediction == 1 else 'Not Suitable',
            'ml_confidence': ml_confidence,
            'logic_prediction': 'Suitable' if logic_assessment['suitable'] else 'Not Suitable',
            'logic_confidence': logic_confidence,
            'assessment_method': 'Combined ML + Enhanced Logic'
        }
        
        logger.info(f"üéØ D·ª± ƒëo√°n k·∫øt h·ª£p cho {result['candidate_id']}: {result['prediction_vietnamese']} (tin c·∫≠y cu·ªëi: {result['confidence']:.3f})")
        
        return result
    
    def get_recommendation_vietnamese(self, prediction, confidence):
        """
        ƒê∆∞a ra khuy·∫øn ngh·ªã b·∫±ng ti·∫øng Vi·ªát d·ª±a tr√™n d·ª± ƒëo√°n
        """
        if prediction == 1:
            if confidence > 0.8:
                return "R·∫•t khuy·∫øn kh√≠ch m·ªùi ph·ªèng v·∫•n ngay"
            elif confidence > 0.7:
                return "Khuy·∫øn kh√≠ch m·ªùi ph·ªèng v·∫•n"
            elif confidence > 0.6:
                return "C√≥ th·ªÉ m·ªùi ph·ªèng v·∫•n"
            else:
                return "C·∫ßn ƒë√°nh gi√° k·ªπ h∆°n trong ph·ªèng v·∫•n"
        else:
            if confidence > 0.7:
                return "Kh√¥ng ph√π h·ª£p v·ªõi v·ªã tr√≠ n√†y"
            elif confidence > 0.5:
                return "C·∫ßn c·∫£i thi·ªán k·ªπ nƒÉng ho·∫∑c xem x√©t v·ªã tr√≠ kh√°c"
            else:
                return "Thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc - kh√¥ng khuy·∫øn kh√≠ch"

    def get_education_vietnamese(self, education_level):
        """Chuy·ªÉn ƒë·ªïi tr√¨nh ƒë·ªô h·ªçc v·∫•n sang ti·∫øng Vi·ªát"""
        education_mapping = {
            'high_school': 'T·ªët nghi·ªáp THPT',
            'associate': 'Cao ƒë·∫≥ng', 
            'bachelor': 'C·ª≠ nh√¢n',
            'master': 'Th·∫°c sƒ©',
            'phd': 'Ti·∫øn sƒ©'
        }
        return education_mapping.get(education_level, 'Kh√¥ng x√°c ƒë·ªãnh')

    def generate_candidate_summary_vietnamese(self, candidate_data, prediction, confidence):
        """T·∫°o t√≥m t·∫Øt ·ª©ng vi√™n b·∫±ng ti·∫øng Vi·ªát"""
        years_exp = candidate_data.get('years_experience', 0)
        education = self.get_education_vietnamese(candidate_data.get('education_level', ''))
        skills_count = len(candidate_data.get('skills', '').split(','))
        position = candidate_data.get('position_applied', 'ch∆∞a x√°c ƒë·ªãnh')
        
        summary = f"·ª®ng vi√™n ·ª©ng tuy·ªÉn v·ªã tr√≠ {position}, c√≥ {years_exp} nƒÉm kinh nghi·ªám, tr√¨nh ƒë·ªô {education}, "
        summary += f"s·ªü h·ªØu {skills_count} k·ªπ nƒÉng ch√≠nh. "
        
        if prediction:
            if confidence > 0.8:
                summary += "ƒê√¢y l√† ·ª©ng vi√™n xu·∫•t s·∫Øc, r·∫•t ph√π h·ª£p v·ªõi v·ªã tr√≠ ·ª©ng tuy·ªÉn."
            elif confidence > 0.7:
                summary += "·ª®ng vi√™n c√≥ ti·ªÅm nƒÉng t·ªët, ph√π h·ª£p v·ªõi v·ªã tr√≠ ·ª©ng tuy·ªÉn."
            else:
                summary += "·ª®ng vi√™n c√≥ th·ªÉ ph√π h·ª£p nh∆∞ng c·∫ßn ƒë√°nh gi√° k·ªπ h∆°n."
        else:
            if confidence > 0.6:
                summary += "·ª®ng vi√™n c·∫ßn c·∫£i thi·ªán k·ªπ nƒÉng ho·∫∑c xem x√©t v·ªã tr√≠ ph√π h·ª£p h∆°n."
            else:
                summary += "·ª®ng vi√™n ch∆∞a ƒë√°p ·ª©ng ƒë·ªß y√™u c·∫ßu cho v·ªã tr√≠ n√†y."
        
        return summary
    
    def batch_predict(self, csv_file):
        """
        D·ª± ƒëo√°n h√†ng lo·∫°t t·ª´ file CSV v·ªõi logic n√¢ng cao
        """
        logger.info(f"üìÅ X·ª≠ l√Ω d·ª± ƒëo√°n h√†ng lo·∫°t t·ª´ file {csv_file} (logic n√¢ng cao)")
        
        df = pd.read_csv(csv_file)
        results = []
        
        total_candidates = len(df)
        logger.info(f"üë• T·ªïng s·ªë ·ª©ng vi√™n c·∫ßn x·ª≠ l√Ω: {total_candidates}")
        
        for idx, row in df.iterrows():
            candidate_data = row.to_dict()
            try:
                result = self.predict_candidate(candidate_data)
                results.append(result)
                
                if (idx + 1) % 10 == 0:
                    logger.info(f"‚è≥ ƒê√£ x·ª≠ l√Ω {idx + 1}/{total_candidates} ·ª©ng vi√™n")
                    
            except Exception as e:
                logger.error(f"‚ùå L·ªói d·ª± ƒëo√°n ·ª©ng vi√™n {candidate_data.get('candidate_id', idx)}: {e}")
                results.append({
                    'candidate_id': candidate_data.get('candidate_id', f'CAND_{idx}'),
                    'prediction': 'Error',
                    'prediction_vietnamese': 'L·ªói',
                    'confidence': 0.0,
                    'probability_suitable': 0.0,
                    'recommendation': 'Processing error',
                    'recommendation_vietnamese': 'L·ªói x·ª≠ l√Ω'
                })
        
        results_df = pd.DataFrame(results)
        
        # Save results
        output_file = self.data_path / f'ket_qua_du_doan_enhanced_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        logger.info(f"üíæ K·∫øt qu·∫£ d·ª± ƒëo√°n n√¢ng cao ƒë√£ l∆∞u t·∫°i {output_file}")
        
        return results_df
    
    def save_model(self):
        """
        L∆∞u m√¥ h√¨nh v√† c√°c th√†nh ph·∫ßn
        """
        try:
            # Save model components
            with open(self.model_path / 'rf_model_enhanced.pkl', 'wb') as f:
                pickle.dump(self.model, f)
            
            with open(self.model_path / 'vectorizer_enhanced.pkl', 'wb') as f:
                pickle.dump(self.vectorizer, f)
            
            with open(self.model_path / 'scaler_enhanced.pkl', 'wb') as f:
                pickle.dump(self.scaler, f)
            
            # Save feature columns
            with open(self.model_path / 'feature_columns_enhanced.json', 'w') as f:
                json.dump(self.feature_columns, f)
            
            # Save position requirements
            with open(self.model_path / 'position_requirements_enhanced.json', 'w', encoding='utf-8') as f:
                json.dump(self.position_requirements, f, ensure_ascii=False, indent=2)
                
            # Save required skills mapping
            with open(self.model_path / 'required_skills_enhanced.json', 'w', encoding='utf-8') as f:
                json.dump(self.required_skills_by_position, f, ensure_ascii=False, indent=2)
            
            logger.info("‚úÖ M√¥ h√¨nh n√¢ng cao ƒë√£ l∆∞u th√†nh c√¥ng")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói l∆∞u m√¥ h√¨nh: {e}")
    
    def load_model(self):
        """
        Load m√¥ h√¨nh ƒë√£ l∆∞u v·ªõi th√¥ng b√°o ti·∫øng Vi·ªát
        """
        try:
            # Try to load enhanced model first
            if (self.model_path / 'rf_model_enhanced.pkl').exists():
                logger.info("üìÇ ƒêang t·∫£i m√¥ h√¨nh n√¢ng cao t·ª´ file...")
                
                with open(self.model_path / 'rf_model_enhanced.pkl', 'rb') as f:
                    self.model = pickle.load(f)
                
                with open(self.model_path / 'vectorizer_enhanced.pkl', 'rb') as f:
                    self.vectorizer = pickle.load(f)
                
                with open(self.model_path / 'scaler_enhanced.pkl', 'rb') as f:
                    self.scaler = pickle.load(f)
                
                with open(self.model_path / 'feature_columns_enhanced.json', 'r') as f:
                    self.feature_columns = json.load(f)
                
                logger.info("‚úÖ T·∫£i m√¥ h√¨nh n√¢ng cao th√†nh c√¥ng!")
                return True
            
            # Fallback to older models
            elif (self.model_path / 'rf_model_improved.pkl').exists():
                logger.info("üìÇ ƒêang t·∫£i m√¥ h√¨nh c·∫£i thi·ªán t·ª´ file...")
                
                with open(self.model_path / 'rf_model_improved.pkl', 'rb') as f:
                    self.model = pickle.load(f)
                
                with open(self.model_path / 'vectorizer_improved.pkl', 'rb') as f:
                    self.vectorizer = pickle.load(f)
                
                with open(self.model_path / 'scaler_improved.pkl', 'rb') as f:
                    self.scaler = pickle.load(f)
                
                with open(self.model_path / 'feature_columns_improved.json', 'r') as f:
                    self.feature_columns = json.load(f)
                
                logger.info("‚úÖ T·∫£i m√¥ h√¨nh c·∫£i thi·ªán th√†nh c√¥ng!")
                return True
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh: {e}")
            return False
    
    def generate_report(self, results_df=None):
        """
        T·∫°o b√°o c√°o t·ªïng h·ª£p n√¢ng cao b·∫±ng ti·∫øng Vi·ªát
        """
        if results_df is None:
            logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu k·∫øt qu·∫£ ƒë·ªÉ t·∫°o b√°o c√°o")
            return {}
        
        total_candidates = len(results_df)
        suitable_candidates = len(results_df[results_df['prediction'] == 'Suitable'])
        avg_confidence = results_df['confidence'].mean()
        
        # Th·ªëng k√™ theo confidence level
        high_confidence_suitable = len(results_df[
            (results_df['prediction'] == 'Suitable') & 
            (results_df['confidence'] > 0.8)
        ])
        
        medium_confidence_suitable = len(results_df[
            (results_df['prediction'] == 'Suitable') & 
            (results_df['confidence'] > 0.6) & 
            (results_df['confidence'] <= 0.8)
        ])
        
        low_confidence_suitable = len(results_df[
            (results_df['prediction'] == 'Suitable') & 
            (results_df['confidence'] <= 0.6)
        ])
        
        report = {
            'total_candidates': total_candidates,
            'suitable_candidates': suitable_candidates,
            'unsuitable_candidates': total_candidates - suitable_candidates,
            'suitable_percentage': (suitable_candidates / total_candidates * 100) if total_candidates > 0 else 0,
            'average_confidence': avg_confidence,
            'high_confidence_suitable': high_confidence_suitable,
            'medium_confidence_suitable': medium_confidence_suitable,
            'low_confidence_suitable': low_confidence_suitable,
            'timestamp': datetime.now().strftime("%d/%m/%Y %H:%M:%S"),
            'summary': f"ƒê√£ x·ª≠ l√Ω {total_candidates} ·ª©ng vi√™n v·ªõi logic k·ªπ nƒÉng n√¢ng cao, trong ƒë√≥ {suitable_candidates} ·ª©ng vi√™n ph√π h·ª£p ({(suitable_candidates / total_candidates * 100):.1f}%)" if total_candidates > 0 else "Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ x·ª≠ l√Ω",
            'system_version': 'HR DSS v3.0 - Enhanced with Required Skills Logic',
            'quality_analysis': {
                'high_confidence_count': high_confidence_suitable,
                'medium_confidence_count': medium_confidence_suitable,
                'low_confidence_count': low_confidence_suitable,
                'recommendation': self.get_quality_recommendation(high_confidence_suitable, medium_confidence_suitable, total_candidates)
            }
        }
        
        # Save report
        report_file = self.data_path / f'bao_cao_nang_cao_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìä B√°o c√°o n√¢ng cao ƒë√£ ƒë∆∞·ª£c t·∫°o v√† l∆∞u t·∫°i {report_file}")
        return report
    
    def get_quality_recommendation(self, high_conf, medium_conf, total):
        """
        ƒê∆∞a ra khuy·∫øn ngh·ªã d·ª±a tr√™n ch·∫•t l∆∞·ª£ng ·ª©ng vi√™n
        """
        if total == 0:
            return "Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch"
        
        high_ratio = high_conf / total
        medium_ratio = medium_conf / total
        
        if high_ratio > 0.3:
            return "Ch·∫•t l∆∞·ª£ng ·ª©ng vi√™n r·∫•t t·ªët, nhi·ªÅu ·ª©ng vi√™n xu·∫•t s·∫Øc"
        elif high_ratio + medium_ratio > 0.5:
            return "Ch·∫•t l∆∞·ª£ng ·ª©ng vi√™n t·ªët, c√≥ th·ªÉ ti·∫øn h√†nh ph·ªèng v·∫•n"
        elif high_ratio + medium_ratio > 0.2:
            return "Ch·∫•t l∆∞·ª£ng ·ª©ng vi√™n trung b√¨nh, c·∫ßn s√†ng l·ªçc k·ªπ h∆°n"
        else:
            return "Ch·∫•t l∆∞·ª£ng ·ª©ng vi√™n th·∫•p, n√™n m·ªü r·ªông ngu·ªìn tuy·ªÉn d·ª•ng"


def main():
    """
    H√†m main ƒë·ªÉ ch·∫°y ·ª©ng d·ª•ng
    """
    parser = argparse.ArgumentParser(description='H·ªá th·ªëng H·ªó tr·ª£ Ra quy·∫øt ƒë·ªãnh Tuy·ªÉn d·ª•ng - Phi√™n b·∫£n N√¢ng cao')
    parser.add_argument('--mode', choices=['train', 'predict', 'batch', 'demo'], 
                       default='demo', help='Ch·∫ø ƒë·ªô ch·∫°y h·ªá th·ªëng')
    parser.add_argument('--input', type=str, help='File ƒë·∫ßu v√†o cho d·ª± ƒëo√°n h√†ng lo·∫°t')
    parser.add_argument('--model-path', type=str, default='models/', 
                       help='ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c m√¥ h√¨nh')
    parser.add_argument('--data-path', type=str, default='data/', 
                       help='ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c d·ªØ li·ªáu')
    
    args = parser.parse_args()
    
    # Initialize system
    hr_system = HRDecisionSupportSystemEnhanced(args.model_path, args.data_path)
    
    if args.mode == 'train':
        logger.info("üß† Ch·∫ø ƒë·ªô hu·∫•n luy·ªán ƒë∆∞·ª£c ch·ªçn (v·ªõi logic k·ªπ nƒÉng n√¢ng cao)")
        accuracy = hr_system.train_model()
        print(f"üéâ Hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t v·ªõi ƒë·ªô ch√≠nh x√°c: {accuracy:.3f}")
    
    elif args.mode == 'predict':
        logger.info("üéØ Ch·∫ø ƒë·ªô d·ª± ƒëo√°n ƒë∆°n (v·ªõi logic k·ªπ nƒÉng n√¢ng cao)")
        # Test case: Data Scientist thi·∫øu SQL
        candidate = {
            'candidate_id': 'TEST_DATA_SCIENTIST',
            'years_experience': 3,
            'education_level': 'bachelor',
            'skills': 'python, machine learning, statistics',  # Thi·∫øu SQL
            'experience_description': '3 nƒÉm kinh nghi·ªám v·ªõi machine learning v√† Python',
            'position_applied': 'data_scientist'
        }
        
        result = hr_system.predict_candidate(candidate)
        print("üìã K·∫øt qu·∫£ d·ª± ƒëo√°n n√¢ng cao:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    elif args.mode == 'batch':
        if not args.input:
            print("‚ùå L·ªói: C·∫ßn file --input cho ch·∫ø ƒë·ªô d·ª± ƒëo√°n h√†ng lo·∫°t")
            return
        
        logger.info(f"üë• Ch·∫ø ƒë·ªô d·ª± ƒëo√°n h√†ng lo·∫°t cho file: {args.input} (v·ªõi logic k·ªπ nƒÉng n√¢ng cao)")
        results = hr_system.batch_predict(args.input)
        report = hr_system.generate_report(results)
        print("‚úÖ D·ª± ƒëo√°n h√†ng lo·∫°t ho√†n t·∫•t v·ªõi logic k·ªπ nƒÉng n√¢ng cao")
        print("üìä B√°o c√°o t·ªïng h·ª£p:")
        print(json.dumps(report, indent=2, ensure_ascii=False))
    
    else:  # demo mode
        logger.info("üéÆ Ch·∫ø ƒë·ªô demo - Ki·ªÉm th·ª≠ logic k·ªπ nƒÉng n√¢ng cao")
        
        # Test multiple scenarios with different skill requirements
        test_cases = [
            {
                'name': 'Data Scientist c√≥ ƒë·ªß k·ªπ nƒÉng b·∫Øt bu·ªôc (SQL + Python)',
                'data': {
                    'candidate_id': 'DS_GOOD',
                    'years_experience': 3,
                    'education_level': 'bachelor',
                    'skills': 'python, sql, machine learning, statistics',
                    'position_applied': 'data_scientist'
                }
            },
            {
                'name': 'Data Scientist thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc (ch·ªâ c√≥ Python, thi·∫øu SQL)',
                'data': {
                    'candidate_id': 'DS_MISSING_SQL',
                    'years_experience': 5,
                    'education_level': 'master',
                    'skills': 'python, machine learning, statistics, deep learning',
                    'position_applied': 'data_scientist'
                }
            },
            {
                'name': 'Web Developer c√≥ ƒë·ªß k·ªπ nƒÉng b·∫Øt bu·ªôc (HTML + CSS + JS)',
                'data': {
                    'candidate_id': 'WEB_GOOD',
                    'years_experience': 2,
                    'education_level': 'bachelor',
                    'skills': 'html, css, javascript, react, nodejs',
                    'position_applied': 'web_developer'
                }
            },
            {
                'name': 'Web Developer thi·∫øu k·ªπ nƒÉng b·∫Øt bu·ªôc (ch·ªâ c√≥ JS, thi·∫øu HTML+CSS)',
                'data': {
                    'candidate_id': 'WEB_MISSING',
                    'years_experience': 4,
                    'education_level': 'bachelor',
                    'skills': 'javascript, react, nodejs, mongodb',
                    'position_applied': 'web_developer'
                }
            },
            {
                'name': 'DevOps Engineer c√≥ k·ªπ nƒÉng ph√π h·ª£p',
                'data': {
                    'candidate_id': 'DEVOPS_GOOD',
                    'years_experience': 4,
                    'education_level': 'bachelor',
                    'skills': 'linux, docker, kubernetes, aws, terraform',
                    'position_applied': 'devops_engineer'
                }
            }
        ]
        
        print("=== KI·ªÇM TH·ª¨ LOGIC K·ª∏ NƒÇNG N√ÇNG CAO ===\n")
        
        for test_case in test_cases:
            print(f"--- {test_case['name']} ---")
            result = hr_system.predict_candidate(test_case['data'])
            
            print(f"K·∫øt qu·∫£: {'‚úì PH√ô H·ª¢P' if result['prediction'] == 'Suitable' else '‚úó CH∆ØA PH√ô H·ª¢P'}")
            print(f"ƒê·ªô tin c·∫≠y: {result['confidence']:.1%}")
            print(f"Khuy·∫øn ngh·ªã: {result['recommendation_vietnamese']}")
            
            # Hi·ªÉn th·ªã ph√¢n t√≠ch k·ªπ nƒÉng chi ti·∫øt
            if 'skill_analysis' in result:
                skill_analysis = result['skill_analysis']
                if skill_analysis['requirements_found']:
                    print("Ph√¢n t√≠ch k·ªπ nƒÉng:")
                    print(f"  - C√≥ ƒë·ªß k·ªπ nƒÉng b·∫Øt bu·ªôc: {'‚úì' if skill_analysis['has_required_skills'] else '‚úó'}")
                    if skill_analysis['missing_required']:
                        print(f"  - Thi·∫øu k·ªπ nƒÉng: {', '.join(skill_analysis['missing_required'])}")
                    if skill_analysis['matching_preferred']:
                        print(f"  - K·ªπ nƒÉng ∆∞u ti√™n: {', '.join(skill_analysis['matching_preferred'])}")
                    if skill_analysis['matching_bonus']:
                        print(f"  - K·ªπ nƒÉng bonus: {', '.join(skill_analysis['matching_bonus'])}")
                    print(f"  - ƒêi·ªÉm k·ªπ nƒÉng: {skill_analysis['skill_score']:.1f}/10")
            
            if 'detailed_feedback' in result:
                print("Chi ti·∫øt ƒë√°nh gi√°:")
                for feedback in result['detailed_feedback']:
                    print(f"  {feedback}")
            
            print()

if __name__ == "__main__":
    main()