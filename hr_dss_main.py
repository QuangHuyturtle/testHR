#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HR Decision Support System - Main Application (Vietnamese Version) - Updated
Há»‡ thá»‘ng há»— trá»£ ra quyáº¿t Ä‘á»‹nh tuyá»ƒn dá»¥ng nhÃ¢n sá»± - PhiÃªn báº£n cáº£i thiá»‡n

Author: Student  
Date: 2025
Course: Há»‡ há»— trá»£ ra quyáº¿t Ä‘á»‹nh, Há»‡ Ä‘iá»u hÃ nh vÃ  láº­p trÃ¬nh Linux
"""

import pandas as pd
import numpy as np
import pickle
import json
import os
import sys
import logging
from datetime import datetime
import argparse
from pathlib import Path

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.pipeline import Pipeline

# Text processing
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Download NLTK data if not exists
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
except LookupError:
    print("Äang táº£i dá»¯ liá»‡u NLTK...")
    nltk.download('punkt')
    nltk.download('stopwords')
    print("âœ“ Táº£i dá»¯ liá»‡u NLTK hoÃ n táº¥t")

# Setup logging
os.makedirs('logs', exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/hr_dss.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class HRDecisionSupportSystem:
    """
    Há»‡ thá»‘ng há»— trá»£ ra quyáº¿t Ä‘á»‹nh tuyá»ƒn dá»¥ng nhÃ¢n sá»± - PhiÃªn báº£n cáº£i thiá»‡n
    """
    
    def __init__(self, model_path="models/", data_path="data/"):
        """
        Khá»Ÿi táº¡o há»‡ thá»‘ng HR DSS
        
        Args:
            model_path (str): ÄÆ°á»ng dáº«n lÆ°u mÃ´ hÃ¬nh
            data_path (str): ÄÆ°á»ng dáº«n dá»¯ liá»‡u
        """
        self.model_path = Path(model_path)
        self.data_path = Path(data_path)
        
        # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
        self.model_path.mkdir(exist_ok=True)
        self.data_path.mkdir(exist_ok=True)
        
        # Initialize components
        self.model = None
        self.vectorizer = None
        self.scaler = None
        self.label_encoder = None
        self.feature_columns = None
        
        # Load position requirements
        self.position_requirements = self.get_position_requirements()
        
        # Load model if exists
        self.load_model()
        
        logger.info("ğŸš€ Há»‡ thá»‘ng Há»— trá»£ Ra quyáº¿t Ä‘á»‹nh Tuyá»ƒn dá»¥ng Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o (PhiÃªn báº£n cáº£i thiá»‡n)")

    def get_position_requirements(self):
        """
        Äá»‹nh nghÄ©a yÃªu cáº§u kinh nghiá»‡m tá»‘i thiá»ƒu cho tá»«ng loáº¡i vá»‹ trÃ­
        """
        return {
            # Vá»‹ trÃ­ cáº¥p cao - yÃªu cáº§u kinh nghiá»‡m cao
            'senior_developer': {'min_years': 5, 'min_education': 'bachelor'},
            'senior_analyst': {'min_years': 5, 'min_education': 'bachelor'}, 
            'data_scientist': {'min_years': 3, 'min_education': 'bachelor'},
            'scientist': {'min_years': 3, 'min_education': 'bachelor'},
            'lead': {'min_years': 4, 'min_education': 'bachelor'},
            'manager': {'min_years': 3, 'min_education': 'bachelor'},
            'director': {'min_years': 7, 'min_education': 'master'},
            
            # Vá»‹ trÃ­ trung cáº¥p
            'developer': {'min_years': 1, 'min_education': 'bachelor'},
            'analyst': {'min_years': 1, 'min_education': 'bachelor'},
            'consultant': {'min_years': 2, 'min_education': 'bachelor'},
            'specialist': {'min_years': 2, 'min_education': 'bachelor'},
            'engineer': {'min_years': 1, 'min_education': 'bachelor'},
            
            # Vá»‹ trÃ­ cÆ¡ báº£n - cÃ³ thá»ƒ cháº¥p nháº­n Ã­t kinh nghiá»‡m hÆ¡n
            'junior_developer': {'min_years': 0, 'min_education': 'bachelor'},
            'junior_analyst': {'min_years': 0, 'min_education': 'bachelor'},
            'intern': {'min_years': 0, 'min_education': 'high_school'},
            'fresher': {'min_years': 0, 'min_education': 'bachelor'},
            'coordinator': {'min_years': 0, 'min_education': 'associate'},
            'designer': {'min_years': 0, 'min_education': 'associate'},
        }

    def get_education_score(self, education_level):
        """Chuyá»ƒn Ä‘á»•i trÃ¬nh Ä‘á»™ há»c váº¥n thÃ nh Ä‘iá»ƒm sá»‘"""
        education_mapping = {
            'high_school': 1,
            'associate': 2, 
            'bachelor': 3,
            'master': 4,
            'phd': 5
        }
        return education_mapping.get(education_level.lower(), 1)

    def improved_suitability_logic(self, candidate_data):
        """
        Logic Ä‘Ã¡nh giÃ¡ cáº£i thiá»‡n vá»›i yÃªu cáº§u kinh nghiá»‡m theo vá»‹ trÃ­
        """
        years_exp = int(candidate_data.get('years_experience', 0))
        education = candidate_data.get('education_level', 'high_school').lower()
        skills = candidate_data.get('skills', '').lower()
        position = candidate_data.get('position_applied', '').lower()
        
        # TÃ¬m yÃªu cáº§u phÃ¹ há»£p nháº¥t cho vá»‹ trÃ­
        position_req = None
        for req_position, req_data in self.position_requirements.items():
            if req_position in position or position in req_position:
                position_req = req_data
                break
        
        # Náº¿u khÃ´ng tÃ¬m tháº¥y yÃªu cáº§u cá»¥ thá»ƒ, sá»­ dá»¥ng yÃªu cáº§u máº·c Ä‘á»‹nh
        if position_req is None:
            # PhÃ¢n loáº¡i dá»±a trÃªn tá»« khÃ³a trong tÃªn vá»‹ trÃ­
            if any(word in position for word in ['senior', 'lead', 'manager', 'director']):
                position_req = {'min_years': 4, 'min_education': 'bachelor'}
            elif any(word in position for word in ['scientist', 'specialist']):
                position_req = {'min_years': 3, 'min_education': 'bachelor'}
            elif any(word in position for word in ['junior', 'intern', 'fresher']):
                position_req = {'min_years': 0, 'min_education': 'bachelor'}
            else:
                position_req = {'min_years': 1, 'min_education': 'bachelor'}  # Máº·c Ä‘á»‹nh
        
        # TÃ­nh Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡
        score = 0
        max_score = 10
        feedback = []
        
        # 1. Kiá»ƒm tra kinh nghiá»‡m (40% trá»ng sá»‘)
        min_years = position_req['min_years']
        if years_exp >= min_years + 2:
            score += 4  # VÆ°á»£t yÃªu cáº§u
            feedback.append(f"âœ“ Kinh nghiá»‡m vÆ°á»£t yÃªu cáº§u ({years_exp} nÄƒm >= {min_years} nÄƒm)")
        elif years_exp >= min_years:
            score += 3  # Äáº¡t yÃªu cáº§u
            feedback.append(f"âœ“ Kinh nghiá»‡m Ä‘áº¡t yÃªu cáº§u ({years_exp} nÄƒm >= {min_years} nÄƒm)")
        elif years_exp >= min_years - 1 and min_years > 0:
            score += 2  # Gáº§n Ä‘áº¡t yÃªu cáº§u
            feedback.append(f"âš  Kinh nghiá»‡m gáº§n Ä‘áº¡t yÃªu cáº§u ({years_exp} nÄƒm, yÃªu cáº§u {min_years} nÄƒm)")
        else:
            score += 0  # KhÃ´ng Ä‘áº¡t yÃªu cáº§u
            feedback.append(f"âœ— Kinh nghiá»‡m chÆ°a Ä‘áº¡t yÃªu cáº§u ({years_exp} nÄƒm < {min_years} nÄƒm)")
        
        # 2. Kiá»ƒm tra há»c váº¥n (25% trá»ng sá»‘)
        min_education = position_req['min_education']
        candidate_edu_score = self.get_education_score(education)
        min_edu_score = self.get_education_score(min_education)
        
        if candidate_edu_score >= min_edu_score + 1:
            score += 2.5  # VÆ°á»£t yÃªu cáº§u
            feedback.append(f"âœ“ Há»c váº¥n vÆ°á»£t yÃªu cáº§u ({education} >= {min_education})")
        elif candidate_edu_score >= min_edu_score:
            score += 2  # Äáº¡t yÃªu cáº§u
            feedback.append(f"âœ“ Há»c váº¥n Ä‘áº¡t yÃªu cáº§u ({education} >= {min_education})")
        else:
            score += 1  # ChÆ°a Ä‘áº¡t yÃªu cáº§u
            feedback.append(f"âœ— Há»c váº¥n chÆ°a Ä‘áº¡t yÃªu cáº§u ({education} < {min_education})")
        
        # 3. Kiá»ƒm tra ká»¹ nÄƒng (35% trá»ng sá»‘)
        valuable_skills = ['python', 'java', 'machine learning', 'leadership', 'project management', 
                          'sql', 'data analysis', 'communication', 'teamwork']
        
        skill_list = [s.strip() for s in skills.split(',')]
        skill_count = len(skill_list)
        valuable_skill_count = sum(1 for skill in valuable_skills if skill in skills)
        
        if valuable_skill_count >= 4 and skill_count >= 6:
            score += 3.5  # Ká»¹ nÄƒng xuáº¥t sáº¯c
            feedback.append(f"âœ“ Ká»¹ nÄƒng xuáº¥t sáº¯c ({valuable_skill_count} ká»¹ nÄƒng giÃ¡ trá»‹, {skill_count} tá»•ng)")
        elif valuable_skill_count >= 2 and skill_count >= 4:
            score += 2.5  # Ká»¹ nÄƒng tá»‘t
            feedback.append(f"âœ“ Ká»¹ nÄƒng tá»‘t ({valuable_skill_count} ká»¹ nÄƒng giÃ¡ trá»‹, {skill_count} tá»•ng)")
        elif valuable_skill_count >= 1:
            score += 1.5  # Ká»¹ nÄƒng cÆ¡ báº£n
            feedback.append(f"âš  Ká»¹ nÄƒng cÆ¡ báº£n ({valuable_skill_count} ká»¹ nÄƒng giÃ¡ trá»‹, {skill_count} tá»•ng)")
        else:
            score += 0.5  # Ká»¹ nÄƒng háº¡n cháº¿
            feedback.append(f"âœ— Ká»¹ nÄƒng háº¡n cháº¿ ({valuable_skill_count} ká»¹ nÄƒng giÃ¡ trá»‹, {skill_count} tá»•ng)")
        
        # TÃ­nh toÃ¡n káº¿t quáº£ cuá»‘i cÃ¹ng
        percentage = (score / max_score) * 100
        
        # Quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng dá»±a trÃªn Ä‘iá»u kiá»‡n nghiÃªm ngáº·t
        suitable = False
        confidence_level = "Tháº¥p"
        
        if score >= 8:  # 80%
            suitable = True
            confidence_level = "Cao"
            recommendation = "Ráº¥t khuyáº¿n khÃ­ch má»i phá»ng váº¥n"
        elif score >= 6.5:  # 65%
            suitable = True  
            confidence_level = "Trung bÃ¬nh"
            recommendation = "Khuyáº¿n khÃ­ch má»i phá»ng váº¥n"
        elif score >= 5:  # 50%
            suitable = False
            confidence_level = "Tháº¥p"
            recommendation = "Cáº§n Ä‘Ã¡nh giÃ¡ thÃªm hoáº·c xem xÃ©t vá»‹ trÃ­ tháº¥p hÆ¡n"
        else:
            suitable = False
            confidence_level = "Ráº¥t tháº¥p"
            recommendation = "KhÃ´ng phÃ¹ há»£p vá»›i vá»‹ trÃ­ nÃ y"
        
        return {
            'suitable': suitable,
            'score': score,
            'max_score': max_score,
            'percentage': percentage,
            'confidence_level': confidence_level,
            'recommendation': recommendation,
            'feedback': feedback,
            'position_requirements': {
                'min_years': min_years,
                'min_education': min_education,
                'position': position
            }
        }
    
    def preprocess_text(self, text):
        """
        Tiá»n xá»­ lÃ½ vÄƒn báº£n (CV, mÃ´ táº£ ká»¹ nÄƒng)
        """
        if pd.isna(text) or text is None:
            return ""
        
        # Chuyá»ƒn vá» chá»¯ thÆ°á»ng
        text = str(text).lower()
        
        # Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, giá»¯ láº¡i chá»¯ cÃ¡i vÃ  sá»‘
        text = re.sub(r'[^a-zA-Z0-9\s]', ' ', text)
        
        # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Tokenize vÃ  loáº¡i bá» stop words
        try:
            tokens = word_tokenize(text)
            stop_words = set(stopwords.words('english'))
            tokens = [token for token in tokens if token not in stop_words and len(token) > 2]
            return ' '.join(tokens)
        except:
            return text
    
    def create_sample_data(self, num_samples=1000):
        """
        Táº¡o dá»¯ liá»‡u máº«u cho training vá»›i logic cáº£i thiá»‡n
        """
        logger.info(f"ğŸ² Táº¡o dá»¯ liá»‡u máº«u vá»›i {num_samples} máº«u (logic cáº£i thiá»‡n)...")
        
        np.random.seed(42)
        
        # Danh sÃ¡ch ká»¹ nÄƒng phá»• biáº¿n
        skills_pool = [
            'python', 'java', 'javascript', 'sql', 'machine learning', 'data analysis',
            'project management', 'communication', 'teamwork', 'leadership',
            'react', 'nodejs', 'docker', 'kubernetes', 'aws', 'azure',
            'agile', 'scrum', 'git', 'linux', 'statistics', 'excel'
        ]
        
        education_levels = ['high_school', 'associate', 'bachelor', 'master', 'phd']
        positions = ['developer', 'analyst', 'manager', 'designer', 'consultant', 
                    'data_scientist', 'senior_developer', 'junior_developer', 'intern', 'fresher']
        
        data = []
        
        for i in range(num_samples):
            # Random features
            years_exp = np.random.randint(0, 20)
            education = np.random.choice(education_levels)
            position = np.random.choice(positions)
            
            # Random skills (2-8 skills per candidate)
            num_skills = np.random.randint(2, 9)
            candidate_skills = np.random.choice(skills_pool, num_skills, replace=False)
            skills_str = ', '.join(candidate_skills)
            
            # Experience description
            exp_desc = f"Worked as {position} for {years_exp} years with expertise in {', '.join(candidate_skills[:3])}"
            
            # Sá»­ dá»¥ng logic cáº£i thiá»‡n Ä‘á»ƒ táº¡o nhÃ£n
            candidate_data = {
                'years_experience': years_exp,
                'education_level': education,
                'skills': skills_str,
                'position_applied': position
            }
            
            assessment = self.improved_suitability_logic(candidate_data)
            suitable = 1 if assessment['suitable'] else 0
            
            data.append({
                'candidate_id': f'CAND_{i+1:04d}',
                'years_experience': years_exp,
                'education_level': education,
                'skills': skills_str,
                'experience_description': exp_desc,
                'position_applied': position,
                'suitable': suitable
            })
        
        df = pd.DataFrame(data)
        
        # Save sample data
        sample_file = self.data_path / 'sample_candidates_improved.csv'
        df.to_csv(sample_file, index=False)
        logger.info(f"âœ“ Dá»¯ liá»‡u máº«u cáº£i thiá»‡n Ä‘Ã£ lÆ°u táº¡i {sample_file}")
        
        return df

    def extract_features(self, df):
        """
        TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u á»©ng viÃªn
        """
        logger.info("ğŸ“Š Äang trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u á»©ng viÃªn...")
        
        # Táº¡o báº£n sao Ä‘á»ƒ khÃ´ng áº£nh hÆ°á»Ÿng dá»¯ liá»‡u gá»‘c
        processed_df = df.copy()
        
        # Tiá»n xá»­ lÃ½ vÄƒn báº£n
        processed_df['skills_processed'] = processed_df['skills'].apply(self.preprocess_text)
        processed_df['experience_description_processed'] = processed_df['experience_description'].apply(self.preprocess_text)
        
        # Káº¿t há»£p cÃ¡c trÆ°á»ng vÄƒn báº£n
        processed_df['combined_text'] = (
            processed_df['skills_processed'] + ' ' + 
            processed_df['experience_description_processed']
        )
        
        # TÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng sá»‘
        processed_df['education_score'] = processed_df['education_level'].apply(self.get_education_score)
        
        # Chuáº©n hÃ³a kinh nghiá»‡m (nÄƒm)
        processed_df['years_experience'] = pd.to_numeric(processed_df['years_experience'], errors='coerce').fillna(0)
        
        # TÃ­nh Ä‘iá»ƒm ká»¹ nÄƒng (sá»‘ lÆ°á»£ng ká»¹ nÄƒng)
        processed_df['num_skills'] = processed_df['skills'].str.count(',') + 1
        processed_df['num_skills'] = processed_df['num_skills'].fillna(0)
        
        logger.info("âœ“ TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng hoÃ n táº¥t")
        return processed_df
    
    def train_model(self, df=None):
        """
        Training mÃ´ hÃ¬nh phÃ¢n loáº¡i vá»›i logic cáº£i thiá»‡n
        """
        logger.info("ğŸ§  Báº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i logic cáº£i thiá»‡n...")
        
        if df is None:
            logger.info("ğŸ“¦ Táº¡o dá»¯ liá»‡u máº«u vá»›i logic cáº£i thiá»‡n...")
            df = self.create_sample_data()
        
        # Extract features
        logger.info("ğŸ”§ TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u...")
        processed_df = self.extract_features(df)
        
        # Prepare text features
        if self.vectorizer is None:
            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        
        logger.info("ğŸ“ Xá»­ lÃ½ Ä‘áº·c trÆ°ng vÄƒn báº£n...")
        text_features = self.vectorizer.fit_transform(processed_df['combined_text'])
        
        # Prepare numerical features
        numerical_cols = ['education_score', 'years_experience', 'num_skills']
        self.feature_columns = numerical_cols
        
        if self.scaler is None:
            self.scaler = StandardScaler()
        
        logger.info("ğŸ“ Chuáº©n hÃ³a Ä‘áº·c trÆ°ng sá»‘...")
        numerical_features = self.scaler.fit_transform(processed_df[numerical_cols])
        
        # Combine features
        X_text = text_features.toarray()
        X_numerical = numerical_features
        X = np.hstack([X_text, X_numerical])
        
        # Target variable
        y = processed_df['suitable']
        
        logger.info(f"ğŸ“Š Tá»•ng sá»‘ máº«u: {len(X)}")
        logger.info(f"ğŸ¯ Sá»‘ Ä‘áº·c trÆ°ng: {X.shape[1]}")
        logger.info(f"âš–ï¸ PhÃ¢n phá»‘i nhÃ£n - PhÃ¹ há»£p: {y.sum()}, ChÆ°a phÃ¹ há»£p: {len(y) - y.sum()}")
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        logger.info(f"ğŸ”¨ Dá»¯ liá»‡u huáº¥n luyá»‡n: {len(X_train)} máº«u")
        logger.info(f"ğŸ” Dá»¯ liá»‡u kiá»ƒm thá»­: {len(X_test)} máº«u")
        
        # Train model
        logger.info("ğŸŒ² Báº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest...")
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        
        self.model.fit(X_train, y_train)
        
        # Evaluate model
        logger.info("ğŸ“ˆ ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh...")
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        logger.info(f"ğŸ‰ Huáº¥n luyá»‡n mÃ´ hÃ¬nh hoÃ n táº¥t!")
        logger.info(f"ğŸ† Äá»™ chÃ­nh xÃ¡c: {accuracy:.3f}")
        logger.info(f"ğŸ“‹ BÃ¡o cÃ¡o phÃ¢n loáº¡i:\n{classification_report(y_test, y_pred)}")
        
        # Save model
        logger.info("ğŸ’¾ LÆ°u mÃ´ hÃ¬nh...")
        self.save_model()
        
        return accuracy
    
    def predict_candidate(self, candidate_data):
        """
        Dá»± Ä‘oÃ¡n Ä‘á»™ phÃ¹ há»£p cá»§a á»©ng viÃªn sá»­ dá»¥ng cáº£ ML model vÃ  logic cáº£i thiá»‡n
        """
        if self.model is None:
            # Náº¿u chÆ°a cÃ³ model, chá»‰ sá»­ dá»¥ng logic cáº£i thiá»‡n
            logger.warning("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh ML, sá»­ dá»¥ng logic Ä‘Ã¡nh giÃ¡ cáº£i thiá»‡n")
            assessment = self.improved_suitability_logic(candidate_data)
            
            result = {
                'candidate_id': candidate_data.get('candidate_id', 'KhÃ´ng xÃ¡c Ä‘á»‹nh'),
                'prediction': 'Suitable' if assessment['suitable'] else 'Not Suitable',
                'prediction_vietnamese': 'PhÃ¹ há»£p' if assessment['suitable'] else 'ChÆ°a phÃ¹ há»£p',
                'confidence': assessment['percentage'] / 100,
                'probability_suitable': assessment['percentage'] / 100,
                'recommendation': assessment['recommendation'],
                'recommendation_vietnamese': assessment['recommendation'],
                'education_display': self.get_education_vietnamese(candidate_data.get('education_level', '')),
                'summary': self.generate_candidate_summary_vietnamese(candidate_data, assessment['suitable'], assessment['percentage'] / 100),
                'detailed_feedback': assessment['feedback'],
                'position_requirements': assessment['position_requirements'],
                'assessment_method': 'Improved Logic Only'
            }
            
            logger.info(f"ğŸ¯ ÄÃ¡nh giÃ¡ logic cho {result['candidate_id']}: {result['prediction_vietnamese']} ({result['confidence']:.3f})")
            return result
        
        # Sá»­ dá»¥ng cáº£ ML model vÃ  logic cáº£i thiá»‡n
        # Convert to DataFrame
        df = pd.DataFrame([candidate_data])
        
        # Extract features
        processed_df = self.extract_features(df)
        
        # Prepare features
        text_features = self.vectorizer.transform(processed_df['combined_text'])
        numerical_features = self.scaler.transform(processed_df[self.feature_columns])
        
        # Combine features
        X_text = text_features.toarray()
        X_numerical = numerical_features
        X = np.hstack([X_text, X_numerical])
        
        # ML Prediction
        ml_prediction = self.model.predict(X)[0]
        ml_probability = self.model.predict_proba(X)[0]
        
        # Logic Assessment
        logic_assessment = self.improved_suitability_logic(candidate_data)
        
        # Combine both approaches (weighted average)
        ml_confidence = max(ml_probability)
        logic_confidence = logic_assessment['percentage'] / 100
        
        # Trá»ng sá»‘: 60% ML, 40% Logic
        final_confidence = 0.6 * ml_confidence + 0.4 * logic_confidence
        
        # Quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng: pháº£i Ä‘áº¡t cáº£ ML vÃ  Logic hoáº·c cÃ³ confidence cao
        final_suitable = (ml_prediction == 1 and logic_assessment['suitable']) or final_confidence > 0.8
        
        result = {
            'candidate_id': candidate_data.get('candidate_id', 'KhÃ´ng xÃ¡c Ä‘á»‹nh'),
            'prediction': 'Suitable' if final_suitable else 'Not Suitable',
            'prediction_vietnamese': 'PhÃ¹ há»£p' if final_suitable else 'ChÆ°a phÃ¹ há»£p',
            'confidence': final_confidence,
            'probability_suitable': final_confidence,
            'recommendation': self.get_recommendation_vietnamese(1 if final_suitable else 0, final_confidence),
            'recommendation_vietnamese': self.get_recommendation_vietnamese(1 if final_suitable else 0, final_confidence),
            'education_display': self.get_education_vietnamese(candidate_data.get('education_level', '')),
            'summary': self.generate_candidate_summary_vietnamese(candidate_data, final_suitable, final_confidence),
            'detailed_feedback': logic_assessment['feedback'],
            'position_requirements': logic_assessment['position_requirements'],
            'ml_prediction': 'Suitable' if ml_prediction == 1 else 'Not Suitable',
            'ml_confidence': ml_confidence,
            'logic_prediction': 'Suitable' if logic_assessment['suitable'] else 'Not Suitable',
            'logic_confidence': logic_confidence,
            'assessment_method': 'Combined ML + Improved Logic'
        }
        
        logger.info(f"ğŸ¯ Dá»± Ä‘oÃ¡n káº¿t há»£p cho {result['candidate_id']}: {result['prediction_vietnamese']} (tin cáº­y cuá»‘i: {result['confidence']:.3f})")
        
        return result
    
    def get_recommendation_vietnamese(self, prediction, confidence):
        """
        ÄÆ°a ra khuyáº¿n nghá»‹ báº±ng tiáº¿ng Viá»‡t dá»±a trÃªn dá»± Ä‘oÃ¡n
        """
        if prediction == 1:
            if confidence > 0.8:
                return "Ráº¥t khuyáº¿n khÃ­ch má»i phá»ng váº¥n"
            elif confidence > 0.6:
                return "Khuyáº¿n khÃ­ch má»i phá»ng váº¥n"
            else:
                return "CÃ¢n nháº¯c má»i phá»ng váº¥n vá»›i thÃ¡i Ä‘á»™ tháº­n trá»ng"
        else:
            if confidence > 0.8:
                return "KhÃ´ng phÃ¹ há»£p vá»›i vá»‹ trÃ­ nÃ y"
            elif confidence > 0.6:
                return "Cáº§n Ä‘Ã¡nh giÃ¡ thÃªm hoáº·c xem xÃ©t vá»‹ trÃ­ tháº¥p hÆ¡n"
            else:
                return "KhÃ´ng khuyáº¿n khÃ­ch"

    def get_education_vietnamese(self, education_level):
        """Chuyá»ƒn Ä‘á»•i trÃ¬nh Ä‘á»™ há»c váº¥n sang tiáº¿ng Viá»‡t"""
        education_mapping = {
            'high_school': 'Tá»‘t nghiá»‡p THPT',
            'associate': 'Cao Ä‘áº³ng', 
            'bachelor': 'Cá»­ nhÃ¢n',
            'master': 'Tháº¡c sÄ©',
            'phd': 'Tiáº¿n sÄ©'
        }
        return education_mapping.get(education_level, 'KhÃ´ng xÃ¡c Ä‘á»‹nh')

    def generate_candidate_summary_vietnamese(self, candidate_data, prediction, confidence):
        """Táº¡o tÃ³m táº¯t á»©ng viÃªn báº±ng tiáº¿ng Viá»‡t"""
        years_exp = candidate_data.get('years_experience', 0)
        education = self.get_education_vietnamese(candidate_data.get('education_level', ''))
        skills_count = len(candidate_data.get('skills', '').split(','))
        position = candidate_data.get('position_applied', 'chÆ°a xÃ¡c Ä‘á»‹nh')
        
        summary = f"á»¨ng viÃªn á»©ng tuyá»ƒn vá»‹ trÃ­ {position}, cÃ³ {years_exp} nÄƒm kinh nghiá»‡m, trÃ¬nh Ä‘á»™ {education}, "
        summary += f"sá»Ÿ há»¯u {skills_count} ká»¹ nÄƒng chÃ­nh. "
        
        if prediction:
            if confidence > 0.8:
                summary += "ÄÃ¢y lÃ  á»©ng viÃªn tiá»m nÄƒng cao, ráº¥t phÃ¹ há»£p vá»›i vá»‹ trÃ­ á»©ng tuyá»ƒn."
            else:
                summary += "á»¨ng viÃªn cÃ³ tiá»m nÄƒng tá»‘t, phÃ¹ há»£p vá»›i vá»‹ trÃ­ á»©ng tuyá»ƒn."
        else:
            if confidence > 0.6:
                summary += "á»¨ng viÃªn cáº§n Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ ká»¹ hÆ¡n hoáº·c xem xÃ©t vá»‹ trÃ­ phÃ¹ há»£p hÆ¡n."
            else:
                summary += "á»¨ng viÃªn chÆ°a Ä‘Ã¡p á»©ng Ä‘á»§ yÃªu cáº§u cho vá»‹ trÃ­ nÃ y."
        
        return summary
    
    def batch_predict(self, csv_file):
        """
        Dá»± Ä‘oÃ¡n hÃ ng loáº¡t tá»« file CSV
        """
        logger.info(f"ğŸ“ Xá»­ lÃ½ dá»± Ä‘oÃ¡n hÃ ng loáº¡t tá»« file {csv_file}")
        
        df = pd.read_csv(csv_file)
        results = []
        
        total_candidates = len(df)
        logger.info(f"ğŸ‘¥ Tá»•ng sá»‘ á»©ng viÃªn cáº§n xá»­ lÃ½: {total_candidates}")
        
        for idx, row in df.iterrows():
            candidate_data = row.to_dict()
            try:
                result = self.predict_candidate(candidate_data)
                results.append(result)
                
                if (idx + 1) % 10 == 0:
                    logger.info(f"â³ ÄÃ£ xá»­ lÃ½ {idx + 1}/{total_candidates} á»©ng viÃªn")
                    
            except Exception as e:
                logger.error(f"âŒ Lá»—i dá»± Ä‘oÃ¡n á»©ng viÃªn {candidate_data.get('candidate_id', idx)}: {e}")
                results.append({
                    'candidate_id': candidate_data.get('candidate_id', f'CAND_{idx}'),
                    'prediction': 'Error',
                    'prediction_vietnamese': 'Lá»—i',
                    'confidence': 0.0,
                    'probability_suitable': 0.0,
                    'recommendation': 'Processing error',
                    'recommendation_vietnamese': 'Lá»—i xá»­ lÃ½'
                })
        
        results_df = pd.DataFrame(results)
        
        # Save results
        output_file = self.data_path / f'ket_qua_du_doan_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        logger.info(f"ğŸ’¾ Káº¿t quáº£ dá»± Ä‘oÃ¡n hÃ ng loáº¡t Ä‘Ã£ lÆ°u táº¡i {output_file}")
        
        return results_df
    
    def save_model(self):
        """
        LÆ°u mÃ´ hÃ¬nh vÃ  cÃ¡c thÃ nh pháº§n
        """
        try:
            # Save model components
            with open(self.model_path / 'rf_model_improved.pkl', 'wb') as f:
                pickle.dump(self.model, f)
            
            with open(self.model_path / 'vectorizer_improved.pkl', 'wb') as f:
                pickle.dump(self.vectorizer, f)
            
            with open(self.model_path / 'scaler_improved.pkl', 'wb') as f:
                pickle.dump(self.scaler, f)
            
            # Save feature columns
            with open(self.model_path / 'feature_columns_improved.json', 'w') as f:
                json.dump(self.feature_columns, f)
            
            # Save position requirements
            with open(self.model_path / 'position_requirements.json', 'w', encoding='utf-8') as f:
                json.dump(self.position_requirements, f, ensure_ascii=False, indent=2)
            
            logger.info("âœ… MÃ´ hÃ¬nh cáº£i thiá»‡n Ä‘Ã£ lÆ°u thÃ nh cÃ´ng")
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i lÆ°u mÃ´ hÃ¬nh: {e}")
    
    def load_model(self):
        """
        Load mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u vá»›i thÃ´ng bÃ¡o tiáº¿ng Viá»‡t
        """
        try:
            # Try to load improved model first
            if (self.model_path / 'rf_model_improved.pkl').exists():
                logger.info("ğŸ“‚ Äang táº£i mÃ´ hÃ¬nh cáº£i thiá»‡n tá»« file...")
                
                with open(self.model_path / 'rf_model_improved.pkl', 'rb') as f:
                    self.model = pickle.load(f)
                
                with open(self.model_path / 'vectorizer_improved.pkl', 'rb') as f:
                    self.vectorizer = pickle.load(f)
                
                with open(self.model_path / 'scaler_improved.pkl', 'rb') as f:
                    self.scaler = pickle.load(f)
                
                with open(self.model_path / 'feature_columns_improved.json', 'r') as f:
                    self.feature_columns = json.load(f)
                
                logger.info("âœ… Táº£i mÃ´ hÃ¬nh cáº£i thiá»‡n thÃ nh cÃ´ng!")
                return True
            
            # Fallback to old model
            elif (self.model_path / 'rf_model.pkl').exists():
                logger.info("ğŸ“‚ Äang táº£i mÃ´ hÃ¬nh cÅ© tá»« file...")
                
                with open(self.model_path / 'rf_model.pkl', 'rb') as f:
                    self.model = pickle.load(f)
                
                with open(self.model_path / 'vectorizer.pkl', 'rb') as f:
                    self.vectorizer = pickle.load(f)
                
                with open(self.model_path / 'scaler.pkl', 'rb') as f:
                    self.scaler = pickle.load(f)
                
                with open(self.model_path / 'feature_columns.json', 'r') as f:
                    self.feature_columns = json.load(f)
                
                logger.info("âœ… Táº£i mÃ´ hÃ¬nh cÅ© thÃ nh cÃ´ng!")
                return True
                
        except Exception as e:
            logger.warning(f"âš ï¸ KhÃ´ng thá»ƒ táº£i mÃ´ hÃ¬nh: {e}")
            return False
    
    def generate_report(self, results_df=None):
        """
        Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p báº±ng tiáº¿ng Viá»‡t
        """
        if results_df is None:
            logger.warning("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u káº¿t quáº£ Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o")
            return {}
        
        total_candidates = len(results_df)
        suitable_candidates = len(results_df[results_df['prediction'] == 'Suitable'])
        avg_confidence = results_df['confidence'].mean()
        
        report = {
            'total_candidates': total_candidates,
            'suitable_candidates': suitable_candidates,
            'unsuitable_candidates': total_candidates - suitable_candidates,
            'suitable_percentage': (suitable_candidates / total_candidates * 100) if total_candidates > 0 else 0,
            'average_confidence': avg_confidence,
            'high_confidence_suitable': len(results_df[
                (results_df['prediction'] == 'Suitable') & 
                (results_df['confidence'] > 0.8)
            ]),
            'timestamp': datetime.now().strftime("%d/%m/%Y %H:%M:%S"),
            'summary': f"ÄÃ£ xá»­ lÃ½ {total_candidates} á»©ng viÃªn vá»›i logic cáº£i thiá»‡n, trong Ä‘Ã³ {suitable_candidates} á»©ng viÃªn phÃ¹ há»£p ({(suitable_candidates / total_candidates * 100):.1f}%)" if total_candidates > 0 else "KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ xá»­ lÃ½",
            'system_version': 'HR DSS v2.0 - Improved Logic'
        }
        
        # Save report
        report_file = self.data_path / f'bao_cao_cai_tien_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š BÃ¡o cÃ¡o cáº£i thiá»‡n Ä‘Ã£ Ä‘Æ°á»£c táº¡o vÃ  lÆ°u táº¡i {report_file}")
        return report


def main():
    """
    HÃ m main Ä‘á»ƒ cháº¡y á»©ng dá»¥ng
    """
    parser = argparse.ArgumentParser(description='Há»‡ thá»‘ng Há»— trá»£ Ra quyáº¿t Ä‘á»‹nh Tuyá»ƒn dá»¥ng - PhiÃªn báº£n Cáº£i thiá»‡n')
    parser.add_argument('--mode', choices=['train', 'predict', 'batch', 'demo'], 
                       default='demo', help='Cháº¿ Ä‘á»™ cháº¡y há»‡ thá»‘ng')
    parser.add_argument('--input', type=str, help='File Ä‘áº§u vÃ o cho dá»± Ä‘oÃ¡n hÃ ng loáº¡t')
    parser.add_argument('--model-path', type=str, default='models/', 
                       help='ÄÆ°á»ng dáº«n thÆ° má»¥c mÃ´ hÃ¬nh')
    parser.add_argument('--data-path', type=str, default='data/', 
                       help='ÄÆ°á»ng dáº«n thÆ° má»¥c dá»¯ liá»‡u')
    
    args = parser.parse_args()
    
    # Initialize system
    hr_system = HRDecisionSupportSystem(args.model_path, args.data_path)
    
    if args.mode == 'train':
        logger.info("ğŸ§  Cháº¿ Ä‘á»™ huáº¥n luyá»‡n Ä‘Æ°á»£c chá»n (vá»›i logic cáº£i thiá»‡n)")
        accuracy = hr_system.train_model()
        print(f"ğŸ‰ Huáº¥n luyá»‡n mÃ´ hÃ¬nh hoÃ n táº¥t vá»›i Ä‘á»™ chÃ­nh xÃ¡c: {accuracy:.3f}")
    
    elif args.mode == 'predict':
        logger.info("ğŸ¯ Cháº¿ Ä‘á»™ dá»± Ä‘oÃ¡n Ä‘Æ¡n (vá»›i logic cáº£i thiá»‡n)")
        # Test case: Data Scientist vá»›i 0 nÄƒm kinh nghiá»‡m
        candidate = {
            'candidate_id': 'GiaHuy_Test',
            'years_experience': 0,
            'education_level': 'bachelor',
            'skills': 'python, machine learning',
            'experience_description': 'Má»›i tá»‘t nghiá»‡p vá»›i kiáº¿n thá»©c cÆ¡ báº£n vá» láº­p trÃ¬nh',
            'position_applied': 'data_scientist'
        }
        
        result = hr_system.predict_candidate(candidate)
        print("ğŸ“‹ Káº¿t quáº£ dá»± Ä‘oÃ¡n cáº£i thiá»‡n:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    elif args.mode == 'batch':
        if not args.input:
            print("âŒ Lá»—i: Cáº§n file --input cho cháº¿ Ä‘á»™ dá»± Ä‘oÃ¡n hÃ ng loáº¡t")
            return
        
        logger.info(f"ğŸ‘¥ Cháº¿ Ä‘á»™ dá»± Ä‘oÃ¡n hÃ ng loáº¡t cho file: {args.input} (vá»›i logic cáº£i thiá»‡n)")
        results = hr_system.batch_predict(args.input)
        report = hr_system.generate_report(results)
        print("âœ… Dá»± Ä‘oÃ¡n hÃ ng loáº¡t hoÃ n táº¥t vá»›i logic cáº£i thiá»‡n")
        print("ğŸ“Š BÃ¡o cÃ¡o tá»•ng há»£p:")
        print(json.dumps(report, indent=2, ensure_ascii=False))
    
    else:  # demo mode
        logger.info("ğŸ® Cháº¿ Ä‘á»™ demo - Kiá»ƒm thá»­ logic cáº£i thiá»‡n")
        
        # Test multiple scenarios
        test_cases = [
            {
                'name': 'Data Scientist vá»›i 0 nÄƒm kinh nghiá»‡m (nhÆ° trÆ°á»ng há»£p GiaHuy)',
                'data': {
                    'candidate_id': 'GiaHuy',
                    'years_experience': 0,
                    'education_level': 'bachelor',
                    'skills': 'python, machine learning',
                    'position_applied': 'data_scientist'
                }
            },
            {
                'name': 'Junior Developer tá»‘t nghiá»‡p má»›i (phÃ¹ há»£p)',
                'data': {
                    'candidate_id': 'JUNIOR001',
                    'years_experience': 0,
                    'education_level': 'bachelor',
                    'skills': 'python, sql, teamwork',
                    'position_applied': 'junior_developer'
                }
            },
            {
                'name': 'Senior Developer kinh nghiá»‡m cao',
                'data': {
                    'candidate_id': 'SENIOR001',
                    'years_experience': 6,
                    'education_level': 'master',
                    'skills': 'python, java, leadership, project management, sql',
                    'position_applied': 'senior_developer'
                }
            }
        ]
        
        print("=== KIá»‚M THá»¬ LOGIC ÄÃNH GIÃ Cáº¢I THIá»†N ===\n")
        
        for test_case in test_cases:
            print(f"--- {test_case['name']} ---")
            result = hr_system.predict_candidate(test_case['data'])
            
            print(f"Káº¿t quáº£: {'âœ“ PHÃ™ Há»¢P' if result['prediction'] == 'Suitable' else 'âœ— CHÆ¯A PHÃ™ Há»¢P'}")
            print(f"Äá»™ tin cáº­y: {result['confidence']:.1%}")
            print(f"Khuyáº¿n nghá»‹: {result['recommendation_vietnamese']}")
            
            if 'detailed_feedback' in result:
                print("Chi tiáº¿t Ä‘Ã¡nh giÃ¡:")
                for feedback in result['detailed_feedback']:
                    print(f"  {feedback}")
            
            if 'position_requirements' in result:
                req = result['position_requirements']
                print(f"YÃªu cáº§u vá»‹ trÃ­: {req['min_years']} nÄƒm kinh nghiá»‡m, {req['min_education']}")
            
            print()

if __name__ == "__main__":
    main()